import os
import re
import requests
import sys
import time

# --- é…ç½®åŒº ---

# GPT-SoVITS APIæ¥å£åœ°å€
API_URL = "http://localhost:9880/tts"
# æ¨¡å‹è·¯å¾„ (è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®)
GPT_WEIGHTS_PATH = "D:\\GPT-SoVITS_\\GPT-SoVITS-v4-20250422fix\\GPT_weights_v4\\zundamon-e10.ckpt"
SOVITS_WEIGHTS_PATH = "D:\\GPT-SoVITS_\\GPT-SoVITS-v4-20250422fix\\SoVITS_weights_v4\\zundamon_e1_s99_l32.pth"

# è‹±æ–‡æ›¿æ¢ä¸ºä¸­æ–‡çš„å¯¹åº”è¡¨ (ä¸åŒºåˆ†å¤§å°å†™)
EN_TO_ZH_MAP = {
    'amazon': 'äºšé©¬é€Š',
    'abema': 'å•Šç™¾é©¬',
    # åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šå¯¹åº”å…³ç³»ï¼Œä¾‹å¦‚:
    'google': 'è°·æ­Œ',
    'youtube': 'æ²¹ç®¡',
    'twitter': 'æ¨ç‰¹',
    'facebook': 'è„¸ä¹¦',
    'instagram': 'å› æ–¯ç‰¹å¤æ‹‰å§†',
    'tver': 'æ¢¯ç“¦å„¿',
    'netflix': 'ç½‘é£',
    'disney': 'è¿ªå£«å°¼',
    'hulu': 'å‘¼å™œ',
    'line': 'çƒ‚',
    'mono': 'è«è¯º',
    'u-next': 'ä¼˜å¥ˆå…‹æ–¯ç‰¹',
    'niconico': 'å¦®å£å¦®å£',
    'at-x': 'è‰¾è¸¢è‰¾å…‹æ–¯',
    'ani-one': 'é˜¿å°¼ç¢—',
    'bilibili': 'å“”å“©å“”å“©',
    'ip': 'å“€åŠˆ',
    'dj': 'ç¼”ç»“',
    'wotagei': 'å“¦å¡”ç›–',
    'call' : 'é ',
    'egoist': 'ä¼Šç‹—æ–¯ç‰¹',
    'sekin': 'å¡å¯å› ',
    'himehina': 'é»‘è“é»‘å‘',
    'vtuber': 'å¾®åå‘—å„¿',
    'hime': 'é»‘è“',
    'hina': 'é»‘å‘',
    'bubblin': 'å·´å¸ƒæ—',
    'nijisanji': 'å½©è™¹ç¤¾',
    'hololive': 'å–‰æ¥¼è±èŠœ',
    'dancehall': 'å½“æ–¯å',
    'echo': 'ä¼Šå£',
    'kizunaai': 'ç»Šçˆ±',
}

# APIè¯·æ±‚å‚æ•°
GPT_SOVITS_PARAMS = {
    # å‚è€ƒéŸ³é¢‘è®¾ç½®
    "ref_audio_path": "D:\\GPT-SoVITS_\\zundamon\\ä»Šæ—¥ã¯æœ€é«˜ã®ä¸€æ—¥ã ã£ãŸï¼èª²é¡Œã¨ã‹å…¨ç„¶ã‚„ã£ã¦ãªã„ã‘ã©ã€ã¾ãã€æ˜æ—¥é ‘å¼µã‚Œã°ã„ã„ã‚ˆã­.wav",
    "prompt_text": "ä»Šæ—¥ã¯æœ€é«˜ã®ä¸€æ—¥ã ã£ãŸï¼èª²é¡Œã¨ã‹å…¨ç„¶ã‚„ã£ã¦ãªã„ã‘ã©ã€ã¾ãã€æ˜æ—¥é ‘å¼µã‚Œã°ã„ã„ã‚ˆã­",
    "prompt_lang": "ja",
    # é»˜è®¤çš„æ–‡æœ¬å’Œè¯­è¨€è®¾ç½®
    "text_lang": "zh",  # å¯é€‰: ja, zh, en
    # åˆæˆå‚æ•°
    "top_k": 5, 
    "top_p": 1, 
    "temperature": 1, 
    "text_split_method": 
    "cut5",
    "batch_size": 1, 
    "batch_threshold": 0.75, 
    "split_bucket": True,
    "speed_factor": 1.15, 
    "fragment_interval": 0.3, 
    "seed": -1,
    "parallel_infer": True, 
    "media_type": "wav", 
    "streaming_mode": False,
    "repetition_penalty": 1.35, 
    "sample_steps": 24, 
    "super_sampling": False,
}

def switch_models(gpt_path, sovits_path):
    """åˆ‡æ¢GPTå’ŒSoVITSæ¨¡å‹"""
    print("\n--- ğŸ”„ æ­£åœ¨åˆ‡æ¢æ¨¡å‹ ---")
    # åˆ‡æ¢GPTæ¨¡å‹
    if gpt_path:
        print(f"  åˆ‡æ¢GPTæ¨¡å‹: {os.path.basename(gpt_path)}")
        try:
            r = requests.get(f"http://127.0.0.1:9880/set_gpt_weights", params={"weights_path": gpt_path}, timeout=20)
            if r.ok and r.json().get("message") == "success": print("  âœ”ï¸ GPTæ¨¡å‹åˆ‡æ¢æˆåŠŸã€‚")
            else: print(f"  âŒ GPTæ¨¡å‹åˆ‡æ¢å¤±è´¥ã€‚çŠ¶æ€ç : {r.status_code}"); return False
        except requests.exceptions.RequestException as e: print(f"  âŒ åˆ‡æ¢GPTæ¨¡å‹æ—¶ç½‘ç»œé”™è¯¯: {e}"); return False
    # åˆ‡æ¢SoVITSæ¨¡å‹
    if sovits_path:
        print(f"  åˆ‡æ¢SoVITSæ¨¡å‹: {os.path.basename(sovits_path)}")
        try:
            r = requests.get(f"http://127.0.0.1:9880/set_sovits_weights", params={"weights_path": sovits_path}, timeout=20)
            if r.ok and r.json().get("message") == "success": print("  âœ”ï¸ SoVITSæ¨¡å‹åˆ‡æ¢æˆåŠŸã€‚")
            else: print(f"  âŒ SoVITSæ¨¡å‹åˆ‡æ¢å¤±è´¥ã€‚çŠ¶æ€ç : {r.status_code}"); return False
        except requests.exceptions.RequestException as e: print(f"  âŒ åˆ‡æ¢SoVITSæ¨¡å‹æ—¶ç½‘ç»œé”™è¯¯: {e}"); return False
    print("--- âœ… æ¨¡å‹åˆ‡æ¢å®Œæˆ ---\n")
    return True

def parse_srt_file(file_path):
    """è§£æSRTæ–‡ä»¶ï¼Œæå–å­—å¹•åºå·å’Œæ–‡æœ¬"""
    print(f"ğŸ” æ­£åœ¨è§£æSRTæ–‡ä»¶: {file_path}")
    try:
        with open(file_path, 'r', encoding='utf-8') as f: content = f.read()
    except Exception as e: print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–SRTæ–‡ä»¶ï¼ŒåŸå› : {e}"); return None
    pattern = re.compile(r'(\d+)\s*\n(?:\d{2}:\d{2}:\d{2},\d{3}\s*-->\s*\d{2}:\d{2}:\d{2},\d{3})\s*\n([\s\S]*?)(?=\n\n|\Z)', re.MULTILINE)
    subtitles = [{'index': m.group(1), 'text': ' '.join(m.group(2).strip().splitlines())} for m in pattern.finditer(content)]
    if subtitles: print(f"âœ… æ‰¾åˆ° {len(subtitles)} æ¡å­—å¹•ã€‚")
    else: print("âš ï¸ è­¦å‘Š: æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„å­—å¹•æ¡ç›®ã€‚")
    return subtitles

def sanitize_filename(text, max_length=50):
    """æ¸…ç†æ–‡æœ¬ï¼Œä½¿å…¶å¯ä»¥å®‰å…¨åœ°ç”¨ä½œæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†ã€‚"""
    sanitized = re.sub(r'[\\/*?:"<>|]', '', text)
    sanitized = sanitized.replace(' ', '')
    return sanitized[:max_length]

def replace_english_words(text):
    """æ ¹æ® EN_TO_ZH_MAP è¡¨ï¼Œå°†æ–‡æœ¬ä¸­çš„è‹±æ–‡å•è¯æ›¿æ¢ä¸ºå¯¹åº”çš„ä¸­æ–‡ã€‚"""
    if not any(c.isalpha() for c in text): return text # å¦‚æœæ²¡æœ‰å­—æ¯ï¼Œç›´æ¥è¿”å›
    def get_replacement(match):
        word = match.group(0)
        return EN_TO_ZH_MAP.get(word.lower(), word) # æŸ¥æ‰¾å°å†™ç‰ˆæœ¬ï¼Œæ‰¾ä¸åˆ°åˆ™è¿”å›åŸè¯
    return re.sub(r'[a-zA-Z]+(?:-[a-zA-Z]+)*', get_replacement, text, flags=re.IGNORECASE)

def generate_audio_for_text(text, text_lang, output_path):
    if os.path.exists(output_path):
        print(f"   âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡åˆæˆ: {os.path.basename(output_path)}")
        return True # æ— éœ€æ‰§è¡Œ
    payload = GPT_SOVITS_PARAMS.copy()
    payload['text'], payload['text_lang'] = text, text_lang
    print(f"   åˆæˆä¸­ (è¯­è¨€: {text_lang}): \"{text[:50]}...\"")
    try:
        response = requests.post(API_URL, json=payload, timeout=120)
        if response.ok and 'audio/wav' in response.headers.get('Content-Type', ''):
            with open(output_path, "wb") as f:
                f.write(response.content)
            print(f"   âœ”ï¸ éŸ³é¢‘å·²ä¿å­˜: {os.path.basename(output_path)}")
            return True
        else:
            print(f"   âŒ APIé”™è¯¯ (çŠ¶æ€ç : {response.status_code}): {response.text[:250]}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"   âŒ ç½‘ç»œé”™è¯¯: æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨ {API_URL}ã€‚åŸå› : {e}")
        return False

def main():
    srt_file_path = "E:\\æŠ½å§å”§\\himehina\\pr.srt"
    output_dir = "E:\\æŠ½å§å”§\\himehina\\sub"
    os.makedirs(output_dir, exist_ok=True)

    if not switch_models(GPT_WEIGHTS_PATH, SOVITS_WEIGHTS_PATH): sys.exit(1)
    subtitles = parse_srt_file(srt_file_path)
    if not subtitles: sys.exit(1)

    total, success_count = len(subtitles), 0
    print(f"\nğŸš€ å¼€å§‹ä¸º {total} æ¡å­—å¹•ç”ŸæˆéŸ³é¢‘...")

    for i, sub in enumerate(subtitles):
        print(f"\n--- å¤„ç†å­—å¹• {i+1}/{total} (åºå·: {sub['index']}) ---")

        # 1. è¯­è¨€è¯†åˆ«å’Œ'|'åˆ†å‰²
        raw_text = sub['text']
        target_lang = GPT_SOVITS_PARAMS['text_lang']
        if raw_text.strip().startswith('j:'):
            target_lang = 'ja'
            text_for_filename = raw_text.strip()[2:].strip()
            print("   æ£€æµ‹åˆ° 'j:' å‰ç¼€ï¼Œè¯­è¨€åˆ‡æ¢ä¸ºæ—¥è¯­ã€‚")
        else:
            text_for_filename = raw_text.strip()
        text_for_filename = text_for_filename.split('|')[0].strip()

        if not text_for_filename:
            print("   âš ï¸ æ–‡æœ¬é¢„å¤„ç†åä¸ºç©ºï¼Œè·³è¿‡æ­¤å­—å¹•ã€‚")
            continue

        # 2. ç”Ÿæˆæ–‡ä»¶å (ä½¿ç”¨æ›¿æ¢å‰çš„æ–‡æœ¬)
        safe_text = sanitize_filename(text_for_filename)
        output_filename = f"{sub['index'].zfill(4)}_{target_lang}_{safe_text}.wav"
        output_filepath = os.path.join(output_dir, output_filename)

        # 3. è‹±æ–‡æ›¿æ¢ (ä»…ç”¨äºè¯­éŸ³åˆæˆ)
        text_for_synthesis = replace_english_words(text_for_filename)
        if text_for_synthesis != text_for_filename:
            print(f"   è‹±æ–‡è¯æ›¿æ¢: \"{text_for_filename}\" -> \"{text_for_synthesis}\"")

        # 4. ç”ŸæˆéŸ³é¢‘
        if generate_audio_for_text(text_for_synthesis, target_lang, output_filepath):
            success_count += 1
        time.sleep(0.5)

    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼æˆåŠŸç”Ÿæˆ {success_count}/{total} ä¸ªæ–‡ä»¶ã€‚è¾“å‡ºç›®å½•: {output_dir}")

if __name__ == "__main__":
    # è¦è¿è¡Œå®Œæ•´çš„SRTå¤„ç†æµç¨‹ï¼Œè¯·å–æ¶ˆä¸‹é¢ä¸€è¡Œçš„æ³¨é‡Š
    main()

    ####### ä¸´æ—¶æµ‹è¯•åŒº #######
    # if not switch_models(GPT_WEIGHTS_PATH, SOVITS_WEIGHTS_PATH): sys.exit(1)
    # output_dir = "E:\\æŠ½å§å”§"
    # os.makedirs(output_dir, exist_ok=True)
    # # æµ‹è¯•æ–‡æœ¬ (åŒ…å«j:å‰ç¼€, |å¿½ç•¥éƒ¨åˆ†, å’Œéœ€è¦æ›¿æ¢çš„è‹±æ–‡)
    # raw_text_to_test = "j:ãƒ‘ã‚¯ãƒã‚½ãƒ³ ä½“æ“"
    # print(f"\n--- è¿è¡Œå•æ¡æ–‡æœ¬æµ‹è¯• ---\nåŸå§‹æ–‡æœ¬: \"{raw_text_to_test}\"")
    # # 1. è¯­è¨€è¯†åˆ«å’Œ'|'åˆ†å‰²
    # target_lang = GPT_SOVITS_PARAMS['text_lang']
    # if raw_text_to_test.strip().startswith('j:'):
    #     target_lang = 'ja'
    #     text_for_filename = raw_text_to_test.strip()[2:].strip()
    #     print("   æ£€æµ‹åˆ° 'j:' å‰ç¼€ï¼Œè¯­è¨€åˆ‡æ¢ä¸ºæ—¥è¯­ã€‚")
    # else:
    #     text_for_filename = raw_text_to_test.strip()
    # text_for_filename = text_for_filename.split('|')[0].strip()
    # # 2. ç”Ÿæˆæ–‡ä»¶å
    # if text_for_filename:
    #     safe_text = sanitize_filename(text_for_filename)
    #     output_filename = f"0000_{target_lang}_{safe_text}.wav"
    #     output_filepath = os.path.join(output_dir, output_filename)
    #     # 3. è‹±æ–‡æ›¿æ¢
    #     text_for_synthesis = replace_english_words(text_for_filename)
    #     if text_for_synthesis != text_for_filename:
    #         print(f"   è‹±æ–‡è¯æ›¿æ¢: \"{text_for_filename}\" -> \"{text_for_synthesis}\"")
    #     # 4. ç”ŸæˆéŸ³é¢‘
    #     generate_audio_for_text(text_for_synthesis, target_lang, output_filepath)